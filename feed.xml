<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://zonca.dev/feed.xml" rel="self" type="application/atom+xml" /><link href="https://zonca.dev/" rel="alternate" type="text/html" /><updated>2020-04-01T16:25:43-05:00</updated><id>https://zonca.dev/feed.xml</id><title type="html">Andrea Zonca</title><subtitle>Tutorials and blog posts by Andrea Zonca: Python, Jupyter, Kubernetes</subtitle><entry><title type="html">Use the Jetstream object store</title><link href="https://zonca.dev/2020/04/jetstream-object-store.html" rel="alternate" type="text/html" title="Use the Jetstream object store" /><published>2020-04-01T00:00:00-05:00</published><updated>2020-04-01T00:00:00-05:00</updated><id>https://zonca.dev/2020/04/jetstream-object-store</id><content type="html" xml:base="https://zonca.dev/2020/04/jetstream-object-store.html">&lt;p&gt;I plan to collect here notes about using the Openstack object store
on Jetstream.&lt;/p&gt;

&lt;h2 id=&quot;get-amazon-style-credentials&quot;&gt;Get Amazon-style credentials&lt;/h2&gt;

&lt;p&gt;Most of the ecosystem is used to Amazon S3, so Openstack Swift provides
Amazon compatible APIs, to access those, make sure your openstack client
can authenticate with the correct allocation, then run:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;openstack ec2 credentials create
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This prints on the screen the Access and the Secret keys, those can be
used in all tools which expects Amazon APIs.&lt;/p&gt;

&lt;h2 id=&quot;command-line-access-to-object-store-with-s3cmd&quot;&gt;Command line access to object store with s3cmd&lt;/h2&gt;

&lt;p&gt;One of the most convenient tools is &lt;code class=&quot;highlighter-rouge&quot;&gt;s3cmd&lt;/code&gt;, which allows to list, upload
and download files from object store. It is included in most linux distributions.&lt;/p&gt;

&lt;p&gt;First run the interactive configuration tool:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;s3cmd --configure
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And set:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Region: &lt;code class=&quot;highlighter-rouge&quot;&gt;RegionOne&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Any password for encryption&lt;/li&gt;
  &lt;li&gt;Use HTTPS: Yes&lt;/li&gt;
  &lt;li&gt;Do not test&lt;/li&gt;
  &lt;li&gt;Save the configuration&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now edit &lt;code class=&quot;highlighter-rouge&quot;&gt;~/.s3cfg&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;set &lt;code class=&quot;highlighter-rouge&quot;&gt;check_ssl_certificate&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;check_ssl_hostname&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;False&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;set &lt;code class=&quot;highlighter-rouge&quot;&gt;host_base=JETSTREAM_SWIFT_ENDPOINT&lt;/code&gt; where &lt;code class=&quot;highlighter-rouge&quot;&gt;JETSTREAM_SWIFT_ENDPOINT&lt;/code&gt; is just the hostname, without &lt;code class=&quot;highlighter-rouge&quot;&gt;https://&lt;/code&gt; and without &lt;code class=&quot;highlighter-rouge&quot;&gt;/swift/v1&lt;/code&gt;, I prefer not to post publicly check on your Openstack dashboard or email me.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now you can list the content of buckets/containers:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; s3cmd ls
2020-03-11 23:25  s3://data_store

&amp;gt; s3cmd ls s3://data_store
                       DIR   s3://data_store/bbb/
                       DIR   s3://data_store/data/
                       DIR   s3://data_store/fff/
2020-03-27 01:39       500   s3://data_store/nginx-cinder.yaml

&amp;gt; s3cmd put local_file.txt s3://data_store/fff/ggg
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html">I plan to collect here notes about using the Openstack object store on Jetstream.</summary></entry><entry><title type="html">Raise and check a flag array with numpy</title><link href="https://zonca.dev/2020/03/raise-check-flag-numpy.html" rel="alternate" type="text/html" title="Raise and check a flag array with numpy" /><published>2020-03-16T00:00:00-05:00</published><updated>2020-03-16T00:00:00-05:00</updated><id>https://zonca.dev/2020/03/raise-check-flag-numpy</id><content type="html" xml:base="https://zonca.dev/2020/03/raise-check-flag-numpy.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-03-16-raise-check-flag-numpy.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Often to describe data quality of timelines or images, we use array of integers where each of its bit has a specific meaning, so that we can identify what issues affect each data point.&lt;/p&gt;
&lt;p&gt;For example we have 10 data points, and we assign an array of 8 bits for data quality.
Generally &lt;code&gt;0&lt;/code&gt; means a good data point, any bit raised is sign of some problem in the data, this is more compressed then using different boolean arrays, and allows to make batch &lt;code&gt;np.bitwise_and&lt;/code&gt; and &lt;code&gt;np.bitwise_or&lt;/code&gt; operations.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uint8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The array uses just 8 bits per element&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;whos&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;Variable   Type       Data/Info
-------------------------------
flag       ndarray    10: 10 elems, type `uint8`, 10 bytes
np         module     &amp;lt;module &amp;#39;numpy&amp;#39; from &amp;#39;/ho&amp;lt;...&amp;gt;kages/numpy/__init__.py&amp;#39;&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Raising a bit seems as easy as adding &lt;code&gt;2**bit&lt;/code&gt; value to the array,
for example the 4th bit is 16, so:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;array([ 0,  0, 16, 16, 16,  0,  0,  0,  0,  0], dtype=uint8)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The issue is that only works if that bit was &lt;code&gt;0&lt;/code&gt;, if it was already raised, we would actually zero it and set the higher bit to 1:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;array([ 0,  0, 32, 16, 16,  0,  0,  0,  0,  0], dtype=uint8)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Use-bitwise-operations&quot;&gt;Use bitwise operations&lt;a class=&quot;anchor-link&quot; href=&quot;#Use-bitwise-operations&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Fortunately &lt;code&gt;numpy&lt;/code&gt; supports bitwise operations that make this easier, see the 2 functions below:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;raise_bit_inplace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;Raise bit of the flag array in place&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    This function modifies the input array,&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    it also works on slices&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Parameters&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    ----------&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    flag : np.array&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        flag bit-array, generally unsigned integer&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    bit : int&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        bit number to raise&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bitwise_or&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;raise_bit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;Raise bit of the flag array&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Parameters&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    ----------&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    flag : np.array&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        flag bit-array, generally unsigned integer&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    bit : int&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        bit number to raise&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Returns&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    -------&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    output_flag : np.array&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        input array with the requested bit raised&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bitwise_or&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;check_bit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;Check if bit of the flag array is raised&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    The output is a boolean array which could&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    be used for slicing another array.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Parameters&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    ----------&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    flag : np.array&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        flag bit-array, generally unsigned integer&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    bit : int&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        bit number to check&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Returns&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    -------&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    is_raised : bool np.array&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        True if the bit is raised, False otherwise    &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bitwise_and&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_bit4_raised&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_bit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_bit4_raised&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;array([False, False, False,  True,  True, False, False, False, False,
       False])&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_bit4_raised&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;They also work with slices of an array:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;raise_bit_inplace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;array([ 0,  0, 32, 16, 16,  0,  2,  2,  2,  2], dtype=uint8)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Running it twice doesn&amp;#39;t change the value of the flag&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;raise_bit_inplace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;array([ 0,  0, 32, 16, 16,  0,  2,  2,  2,  2], dtype=uint8)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;check_bit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;array([False, False, False, False, False, False,  True,  True,  True,
        True])&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;First blog post using a Jupyter Notebook with &lt;a href=&quot;https://github.com/fastai/fastpages#writing-blog-posts-with-jupyter&quot;&gt;fastpages&lt;/a&gt;!!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Setup HTTPS on Kubernetes with Letsencrypt</title><link href="https://zonca.dev/2020/03/setup-https-kubernetes-letsencrypt.html" rel="alternate" type="text/html" title="Setup HTTPS on Kubernetes with Letsencrypt" /><published>2020-03-13T00:00:00-05:00</published><updated>2020-03-13T00:00:00-05:00</updated><id>https://zonca.dev/2020/03/setup-https-kubernetes-letsencrypt</id><content type="html" xml:base="https://zonca.dev/2020/03/setup-https-kubernetes-letsencrypt.html">&lt;p&gt;This is a follow-up to the Magnum-based deployment running on Jetstream,
see &lt;a href=&quot;https://zonca.github.io/2019/06/kubernetes-jupyterhub-jetstream-magnum.html&quot;&gt;my recent tutorial about that&lt;/a&gt;, however it is not specific to that deployment strategy.&lt;/p&gt;

&lt;p&gt;First make sure your payload, for example JupyterHub, is working without HTTPS, so that you check that the ports are open, Ingress is working, and JupyterHub itself can accept connections.&lt;/p&gt;

&lt;p&gt;Let’s follow the &lt;a href=&quot;https://cert-manager.io/docs/installation/kubernetes/&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cert-manager&lt;/code&gt; documentation&lt;/a&gt;, for convenience I pasted the commands below:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create namespace cert-manager
kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v0.14.0/cert-manager-legacy.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once we have &lt;code class=&quot;highlighter-rouge&quot;&gt;cert-manager&lt;/code&gt; setup we can create a Issuer in the &lt;code class=&quot;highlighter-rouge&quot;&gt;jhub&lt;/code&gt; workspace,
(first edit the &lt;code class=&quot;highlighter-rouge&quot;&gt;yml&lt;/code&gt; and add your email address):&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create -f setup_https/https_issuer.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then we modify the JupyterHub ingress configuration to use this Issuer,
modify &lt;code class=&quot;highlighter-rouge&quot;&gt;secrets.yaml&lt;/code&gt; to:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ingress:
  enabled: true
  annotations:
    kubernetes.io/ingress.class: &quot;nginx&quot;    
    cert-manager.io/issuer: &quot;letsencrypt&quot;
  hosts:
      - js-XXX-YYY.jetstream-cloud.org
  tls:
      - hosts:
         - js-XXX-YYY.jetstream-cloud.org
        secretName: certmanager-tls-jupyterhub
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally update the JupyterHub deployment rerunning the deployment script (no need to delete it):&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;bash install_jhub.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html">This is a follow-up to the Magnum-based deployment running on Jetstream, see my recent tutorial about that, however it is not specific to that deployment strategy.</summary></entry><entry><title type="html">Kill Jupyter Notebook servers</title><link href="https://zonca.dev/2020/03/kill-jupyter-notebook.html" rel="alternate" type="text/html" title="Kill Jupyter Notebook servers" /><published>2020-03-12T00:00:00-05:00</published><updated>2020-03-12T00:00:00-05:00</updated><id>https://zonca.dev/2020/03/kill-jupyter-notebook</id><content type="html" xml:base="https://zonca.dev/2020/03/kill-jupyter-notebook.html">&lt;p&gt;Just today I learned how to properly stop previously running Jupyter Notebook
servers, here for future reference:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jupyter notebook stop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is going to print all the ports of the currently running servers.
Choose which ones to stop then:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jupyter notebook stop PORTNUMBER
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html">Just today I learned how to properly stop previously running Jupyter Notebook servers, here for future reference:</summary></entry><entry><title type="html">Migrate from Pelican to Fastpages</title><link href="https://zonca.dev/2020/03/pelican-to-fastpages.html" rel="alternate" type="text/html" title="Migrate from Pelican to Fastpages" /><published>2020-03-09T00:00:00-05:00</published><updated>2020-03-09T00:00:00-05:00</updated><id>https://zonca.dev/2020/03/pelican-to-fastpages</id><content type="html" xml:base="https://zonca.dev/2020/03/pelican-to-fastpages.html">&lt;p&gt;I have been using the Pelican static website generator for a few years,
hosting the content on Github, automatically build on push via Travis-CI
and deploy on Github pages to &lt;code class=&quot;highlighter-rouge&quot;&gt;zonca.github.io&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I am a heavy Jupyter Notebook user so once I saw the announcement of &lt;a href=&quot;https://fastpages.fast.ai/&quot;&gt;Fastpages&lt;/a&gt;
I decided it was time to switch.
I loved the idea of having Jupyter Notebooks built-in and not added via plugins,
also great idea to use Github actions.&lt;/p&gt;

&lt;p&gt;Only issue I found was that you cannot setup Fastpages on &lt;code class=&quot;highlighter-rouge&quot;&gt;username.github.io&lt;/code&gt;,
so went for using a custom domain name instead.&lt;/p&gt;

&lt;h2 id=&quot;import-content&quot;&gt;Import content&lt;/h2&gt;

&lt;p&gt;I created a script, in Python of course, to modify the front matter of the markdown
posts from the Pelican formatting to Jekyll, see &lt;a href=&quot;https://gist.github.com/zonca/b4a5a44513854e1c8918743d219f5f34&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pelican_to_jekyll.py&lt;/code&gt;&lt;/a&gt;.
It also renames the files, because Jekyll expects a date at the beginning of filenames.&lt;/p&gt;

&lt;h2 id=&quot;setup-paginate&quot;&gt;Setup paginate&lt;/h2&gt;

&lt;p&gt;Currently Fastpages doesn’t support pagination for the homepage,
but &lt;a href=&quot;https://github.com/fastai/fastpages/issues/48#issuecomment-596608688&quot;&gt;implemented a workaround&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Update 12 March 2020&lt;/strong&gt;: Now &lt;code class=&quot;highlighter-rouge&quot;&gt;fastpages&lt;/code&gt; supports pagination natively! see &lt;a href=&quot;https://github.com/fastai/fastpages&quot;&gt;the documentation&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;redirect-from-the-old-github-pages-blog&quot;&gt;Redirect from the old Github Pages blog&lt;/h2&gt;

&lt;p&gt;I modified the permalinks of Fastpages so that I have the same URLs in the old and new websites,
just the domain changes.
Github pages does not support custom rewriting rules, so I modified the Pelican template
to put a custom redirection tag in each HTML header.&lt;/p&gt;

&lt;p&gt;In the Pelican template &lt;code class=&quot;highlighter-rouge&quot;&gt;article.html&lt;/code&gt;, in the &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;header&amp;gt;&lt;/code&gt; section I added:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;meta http-equiv=&quot;refresh&quot; content=&quot;0; URL=https://zonca.dev/{{ article.url }}&quot;&amp;gt;
&amp;lt;link rel=&quot;canonical&quot; href=&quot;https://zonca.dev/{{ article.url }}&quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So that Pelican regenerated all the articles with their original address
and automatically redirects upon access.
The canonical link hopefully helps with SEO.&lt;/p&gt;

&lt;p&gt;Did the same with the &lt;code class=&quot;highlighter-rouge&quot;&gt;index.html&lt;/code&gt; template to redirect the homepage,
this depends on your template:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;meta http-equiv=&quot;refresh&quot; content=&quot;0; URL=https://zonca.dev&quot;&amp;gt;
&amp;lt;link rel=&quot;canonical&quot; href=&quot;https://zonca.dev/&quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;screenshots-of-the-old-blog&quot;&gt;Screenshots of the old blog&lt;/h2&gt;

&lt;p&gt;Yeah, for posterity, growing older I get more nostalgic.&lt;/p&gt;

&lt;p&gt;The homepage:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/old_blog_homepage.png&quot; alt=&quot;Old blog homepage&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A section of an article page:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/old_blog_article_page.png&quot; alt=&quot;Old blog article page&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">I have been using the Pelican static website generator for a few years, hosting the content on Github, automatically build on push via Travis-CI and deploy on Github pages to zonca.github.io.</summary></entry><entry><title type="html">Deploy CVMFS on Kubernetes</title><link href="https://zonca.dev/2020/02/cvmfs-kubernetes.html" rel="alternate" type="text/html" title="Deploy CVMFS on Kubernetes" /><published>2020-02-26T13:00:00-06:00</published><updated>2020-02-26T13:00:00-06:00</updated><id>https://zonca.dev/2020/02/cvmfs-kubernetes</id><content type="html" xml:base="https://zonca.dev/2020/02/cvmfs-kubernetes.html">&lt;p&gt;&lt;a href=&quot;https://cvmfs.readthedocs.io/&quot;&gt;CVMFS&lt;/a&gt; is a software distribution service, it is used by High Energy Physics experiments at CERN
to synchronize software environments across the whole collaborations.&lt;/p&gt;

&lt;p&gt;In the context of a Kubernetes + JupyterHub deployment on Jetstream, for example &lt;a href=&quot;http://zonca.github.io/2019/06/kubernetes-jupyterhub-jetstream-magnum.html&quot;&gt;deployed using Magnum following my tutorial&lt;/a&gt;, it is useful to use CVMFS to make the software tools of a collaboration to all the users connected to JupyterHub, so that we can keep the base Docker image simpler and smaller.&lt;/p&gt;

&lt;h2 id=&quot;alternatives&quot;&gt;Alternatives&lt;/h2&gt;

&lt;p&gt;A already existing solution is &lt;a href=&quot;https://github.com/cernops/cvmfs-csi&quot;&gt;the CVMFS CSI driver&lt;/a&gt;, however it doesn’t have much documentation, so I haven’t tested it. It would be useful for larger deployments, but we are designing for a 5 (possibly up to 10) nodes Kubernetes cluster.&lt;/p&gt;

&lt;h2 id=&quot;architecture&quot;&gt;Architecture&lt;/h2&gt;

&lt;p&gt;We have a pod running in Kubernetes (running as a privileged Docker container) which runs the CVMFS client and caches locally
(on a dedicated Openstack volume) some pre-defined CVMFS repositories (at the moment we do not support automounting).&lt;/p&gt;

&lt;p&gt;Currently we are using the &lt;code class=&quot;highlighter-rouge&quot;&gt;DIRECT&lt;/code&gt; connection for the CVMFS client, due to having just a single client which accesses
a small amount of data. Using a proxy is required instead for heavier usage, and it could also be deployed inside Kubernetes.&lt;/p&gt;

&lt;p&gt;The same pod also runs a NFS server and exposes it internally into the Kubernetes cluster, over the local Jetstream network,
to any other pod which can use a NFS volume and mount it to the &lt;code class=&quot;highlighter-rouge&quot;&gt;/cvmfs&lt;/code&gt; folder inside the container.
We also activate the CVMFS configuration options for NFS support, following the &lt;a href=&quot;https://cvmfs.readthedocs.io/en/stable/cpt-configure.html#nfs-server-mode&quot;&gt;documentation&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;deployment&quot;&gt;Deployment&lt;/h2&gt;

&lt;p&gt;The repositories used in this deployment are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/zonca/docker-cvmfs-client&quot;&gt;Github repository for the Docker image of the CVMFS client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Docker Hub repositories where the 2 containers are built: &lt;a href=&quot;https://hub.docker.com/r/zonca/cvmfs-client&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cvmfs-client&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://hub.docker.com/r/zonca/cvmfs-client-nfs&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cvmfs-client-nfs&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;The &lt;a href=&quot;https://github.com/zonca/jupyterhub-deploy-kubernetes-jetstream/tree/master/cvmfs&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;jupyterhub-deploy-kubernetes-jetstream&lt;/code&gt;&lt;/a&gt; Github repositories with the Kubernetes configuration files&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;First we need to checkout the &lt;code class=&quot;highlighter-rouge&quot;&gt;jupyterhub-deploy-kubernetes-jetstream&lt;/code&gt; repository:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone https://github.com/zonca/jupyterhub-deploy-kubernetes-jetstream.git
cd jupyterhub-deploy-kubernetes-jetstream/cvmfs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then configure the CVMFS pod with the required repositories, see the &lt;code class=&quot;highlighter-rouge&quot;&gt;CVMFS_REPOSITORIES&lt;/code&gt; variable in &lt;a href=&quot;https://github.com/zonca/jupyterhub-deploy-kubernetes-jetstream/blob/master/cvmfs/pod_cvmfs_nfs.yaml&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pod_cvmfs_nfs.yaml&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Then deploy the pod with:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create -f pod_cvmfs_nfs.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This creates 2 Openstack volumes, a 20 GB volume for the CVMFS cache, and a 1 GB volume which is just necessary as the &lt;code class=&quot;highlighter-rouge&quot;&gt;/cvmfs&lt;/code&gt; root folder of the NFS server.
It also creates the &lt;code class=&quot;highlighter-rouge&quot;&gt;nfs-service&lt;/code&gt; Service, with a fixed IP, so that we can use it in the pod using this.&lt;/p&gt;

&lt;p&gt;Finally we can create a pod using mounting the folder via NFS:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create -f test_nfs_mount.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then get a terminal in the pod with:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;bash ../terminal_pod.sh test-nfs-mount
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This creates a volume which mounts the &lt;code class=&quot;highlighter-rouge&quot;&gt;/cvmfs&lt;/code&gt; folder shared with NFS, this automatically also shares also all the subfolders.&lt;/p&gt;

&lt;p&gt;Finally we can check the content of the &lt;code class=&quot;highlighter-rouge&quot;&gt;/cvmfs&lt;/code&gt; folder.&lt;/p&gt;</content><author><name></name></author><summary type="html">CVMFS is a software distribution service, it is used by High Energy Physics experiments at CERN to synchronize software environments across the whole collaborations.</summary></entry><entry><title type="html">Organize calendars for a large scientific collaboration</title><link href="https://zonca.dev/2019/12/organize-calendar-collaboration.html" rel="alternate" type="text/html" title="Organize calendars for a large scientific collaboration" /><published>2019-12-02T12:00:00-06:00</published><updated>2019-12-02T12:00:00-06:00</updated><id>https://zonca.dev/2019/12/organize-calendar-collaboration</id><content type="html" xml:base="https://zonca.dev/2019/12/organize-calendar-collaboration.html">&lt;p&gt;Many scientific collaborations have a central calendar, often hosted on Google Calendar,
to coordinate Teleconferences, meetings and events across timezones.&lt;/p&gt;

&lt;h3 id=&quot;the-issue&quot;&gt;The issue&lt;/h3&gt;

&lt;p&gt;Most users are only interested in a small subset of the events, however Google Calendar
does not allow them to subscribe to single events. The central calendar admin could invite
each person to events, but that requires lots of work.&lt;/p&gt;

&lt;p&gt;So, users either subscribe to the whole calendar, but then have a huge clutter of un-interesting events,
or copy just a subset of the events to their calendars, but loose track of any rescheduling of the
original event.&lt;/p&gt;

&lt;h3 id=&quot;proposed-solution&quot;&gt;Proposed solution&lt;/h3&gt;

&lt;p&gt;I recommend to split the events across multiple calendars, for example one for each working group,
or any other categorization where most users would be interested in all events in a calendar.
And possibly a “General” category with events that should interest the whole collaboration.&lt;/p&gt;

&lt;p&gt;Still, we can embed all of the calendars in a single webpage, see an example below where 2 calendars (Monday and Tuesday telecon calendars) are visualized together, &lt;a href=&quot;https://support.google.com/calendar/answer/41207?hl=en&quot;&gt;see the Google Calendar documentation&lt;/a&gt;.&lt;/p&gt;

&lt;iframe src=&quot;https://calendar.google.com/calendar/embed?height=600&amp;amp;wkst=1&amp;amp;bgcolor=%23ffffff&amp;amp;ctz=America%2FLos_Angeles&amp;amp;src=dTI2dnBkNnZvcm1qNHVucnVtajMzZzdwcGNAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ&amp;amp;src=c2FwazM1OTVmcHRiZHVtOWdqZnJwdWxkbnNAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ&amp;amp;color=%23DD4477&amp;amp;color=%236633CC&quot; style=&quot;border-width:0&quot; width=&quot;800&quot; height=&quot;600&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Users can click on the bottom “Add to Google Calendar” button and subscribe to a subset or all the calendars.
See the screenshot below, &lt;img src=&quot;/images/add_google_calendar.png&quot; alt=&quot;screenshot of add to Google Calendar&quot; /&gt;.&lt;/p&gt;

&lt;p&gt;As an additional benefit, we can compartimentalize permissions more easily, e.g. leads of a working group
get writing access only to their relevant calendar/calendars.&lt;/p&gt;</content><author><name></name></author><summary type="html">Many scientific collaborations have a central calendar, often hosted on Google Calendar, to coordinate Teleconferences, meetings and events across timezones.</summary></entry><entry><title type="html">Simulate users on JupyterHub</title><link href="https://zonca.dev/2019/10/loadtest-jupyterhub.html" rel="alternate" type="text/html" title="Simulate users on JupyterHub" /><published>2019-10-30T12:00:00-05:00</published><updated>2019-10-30T12:00:00-05:00</updated><id>https://zonca.dev/2019/10/loadtest-jupyterhub</id><content type="html" xml:base="https://zonca.dev/2019/10/loadtest-jupyterhub.html">&lt;p&gt;I currently have 2 different strategies to deploy JupyterHub on top of Kubernetes on Jetstream:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Using &lt;a href=&quot;https://zonca.github.io/2019/02/kubernetes-jupyterhub-jetstream-kubespray.html&quot;&gt;Kubespray&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Using &lt;a href=&quot;http://zonca.github.io/2019/06/kubernetes-jupyterhub-jetstream-magnum.html&quot;&gt;Magnum&lt;/a&gt;, which also supports the &lt;a href=&quot;http://zonca.github.io/2019/09/kubernetes-jetstream-autoscaler.html&quot;&gt;Cluster Autoscaler&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this tutorial I’ll show how to use Yuvi Pandas’ &lt;a href=&quot;https://github.com/yuvipanda/hubtraf&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;hubtraf&lt;/code&gt;&lt;/a&gt; to simulate load on JupyterHub, i.e. programmatically generate a predefined number of users connecting and executing notebooks on the system.&lt;/p&gt;

&lt;p&gt;This is especially useful to test the Cluster Autoscaler.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;hubtraf&lt;/code&gt; assumes you are using the Dummy authenticator, which is the default installed by the &lt;code class=&quot;highlighter-rouge&quot;&gt;zero-to-jupyterhub&lt;/code&gt; helm chart. If you have configured another authenticator, temporarily disable it for testing purposes.&lt;/p&gt;

&lt;p&gt;First go through the &lt;a href=&quot;https://github.com/yuvipanda/hubtraf/blob/master/docs/index.rst#jupyterhub-traffic-simulator&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;hubtraf&lt;/code&gt; documentation&lt;/a&gt; to understand its functionalities.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;hubtraf&lt;/code&gt; also has a Helm recipe to run it within Kubernetes, but the simpler way is to test from your laptop, follow the [documentation of &lt;code class=&quot;highlighter-rouge&quot;&gt;hubtraf&lt;/code&gt;] to install the package and then run:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hubtraf http://js-xxx-yyy.jetstream-cloud.org 2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To simulate 2 users connecting to the system, you can then check with:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get pods -n jhub
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;That the pods are being created successfully and check the logs on the command line from &lt;code class=&quot;highlighter-rouge&quot;&gt;hubtraf&lt;/code&gt; which explains what it is doing and tracks the time every operation takes, so it is useful to debug any delay in providing resources to users.&lt;/p&gt;

&lt;p&gt;Consider that volumes created by JupyterHub for the test users will remain in Kubernetes and in Openstack, therefore if you would like to use the same deployment for production, remember to cleanup the Kubernetes &lt;code class=&quot;highlighter-rouge&quot;&gt;PersistentVolume&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;PersistentVolumeClaim&lt;/code&gt; resources.&lt;/p&gt;

&lt;p&gt;Now we can test scalability of the deployment with:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    hubtraf http://js-xxx-yyy.jetstream-cloud.org 100
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Make sure you have asked the XSEDE support to increase the maximum number of volumes in Openstack in your allocation that by default is only 10. Otherwise edit &lt;code class=&quot;highlighter-rouge&quot;&gt;config_standard_storage.yaml&lt;/code&gt; and set:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;singleuser:
  storage:
    type: none
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;test-the-cluster-autoscaler&quot;&gt;Test the Cluster Autoscaler&lt;/h2&gt;

&lt;p&gt;If you followed the tutorial to deploy the Cluster Autoscaler on Magnum, you can launch &lt;code class=&quot;highlighter-rouge&quot;&gt;hubtraf&lt;/code&gt; to create a large number of pods, then check that some pods are “Running” and the ones that do not fit in the current nodes are “Pending”:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get pods -n jhub
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and then check in the logs of the autoscaler that it detects that those pods are pending and requests additional nodes.
For example:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; kubectl logs &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; kube-system cluster-autoscaler-hhhhhhh-uuuuuuu
I1031 00:48:39.807384       1 scale_up.go:689] Scale-up: setting group DefaultNodeGroup size to 2
I1031 00:48:41.583449       1 magnum_nodegroup.go:101] Increasing size by 1, 1-&amp;gt;2
I1031 00:49:14.141351       1 magnum_nodegroup.go:67] Waited &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;cluster UPDATE_IN_PROGRESS status
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After 4 or 5 minutes the new node should be available and should show up in:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get nodes
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And we can check that some user pods are now running on the new node:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get pods -n jhub -o wide
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In my case the Autoscaler actually requested a 3rd node to accomodate all the users pods:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;I1031 00:48:39.807384       1 scale_up.go:689] Scale-up: setting group DefaultNodeGroup size to 2
I1031 00:48:41.583449       1 magnum_nodegroup.go:101] Increasing size by 1, 1-&amp;gt;2
I1031 00:49:14.141351       1 magnum_nodegroup.go:67] Waited &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;cluster UPDATE_IN_PROGRESS status
I1031 00:52:51.308054       1 magnum_nodegroup.go:67] Waited &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;cluster UPDATE_COMPLETE status
I1031 00:53:01.315179       1 scale_up.go:689] Scale-up: setting group DefaultNodeGroup size to 3
I1031 00:53:02.996583       1 magnum_nodegroup.go:101] Increasing size by 1, 2-&amp;gt;3
I1031 00:53:35.607158       1 magnum_nodegroup.go:67] Waited &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;cluster UPDATE_IN_PROGRESS status
I1031 00:56:41.834151       1 magnum_nodegroup.go:67] Waited &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;cluster UPDATE_COMPLETE status
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Moreover Cluster Autoscaler also provides useful information in the status of each “Pending” node. For example if it detects that it is useless to create a new node because the node is “Pending” for some other reason (e.g. volume quota reached), this infomation will be accessible using:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl describe node -n jhub jupyter-xxxxxxx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When the simulated users disconnect, &lt;code class=&quot;highlighter-rouge&quot;&gt;hubtraf&lt;/code&gt; has a default of about 5 minutes, the autoscaler waits for the configured amount of minutes, by default it is 10 minutes, in my deployment it is 1 minute to simplify testing, see the &lt;code class=&quot;highlighter-rouge&quot;&gt;cluster-autoscaler-deployment-master.yaml&lt;/code&gt; file.
After this delay, the autoscaler scales down the size of the cluster, it is a 2 step process, it first terminates the Openstack Virtual machine and then adjusts the size of the Magnum cluster (&lt;code class=&quot;highlighter-rouge&quot;&gt;node_count&lt;/code&gt;), you can monitor the process using &lt;code class=&quot;highlighter-rouge&quot;&gt;openstack server list&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;openstack coe cluster list&lt;/code&gt;, and the log of the autoscaler:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;I1101 06:31:10.223660       1 scale_down.go:882] Scale-down: removing empty node k8s-e2iw7axmhym7-minion-1 
I1101 06:31:16.081223       1 magnum_manager_heat.go:276] Waited &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;stack UPDATE_IN_PROGRESS status
I1101 06:32:17.061860       1 magnum_manager_heat.go:276] Waited &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;stack UPDATE_COMPLETE status
I1101 06:32:49.826439       1 magnum_nodegroup.go:67] Waited &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;cluster UPDATE_IN_PROGRESS status
I1101 06:33:21.588022       1 magnum_nodegroup.go:67] Waited &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;cluster UPDATE_COMPLETE status
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;acknowledgments&quot;&gt;Acknowledgments&lt;/h2&gt;

&lt;p&gt;Thanks Yuvi Panda for providing &lt;code class=&quot;highlighter-rouge&quot;&gt;hubtraf&lt;/code&gt;, thanks Julien Chastang for testing my deployments.&lt;/p&gt;</content><author><name></name></author><summary type="html">I currently have 2 different strategies to deploy JupyterHub on top of Kubernetes on Jetstream:</summary></entry><entry><title type="html">Execute Jupyter Notebooks not interactively</title><link href="https://zonca.dev/2019/09/batch-notebook-execution.html" rel="alternate" type="text/html" title="Execute Jupyter Notebooks not interactively" /><published>2019-09-23T12:00:00-05:00</published><updated>2019-09-23T12:00:00-05:00</updated><id>https://zonca.dev/2019/09/batch-notebook-execution</id><content type="html" xml:base="https://zonca.dev/2019/09/batch-notebook-execution.html">&lt;p&gt;Over the years, I have explored how to scale up easily computation through
Jupyter Notebooks by executing them not-interactively, possibily parametrized
and remotely. This is mostly for reference.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/zonca/nbsubmit&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;nbsubmit&lt;/code&gt;&lt;/a&gt; is a Python package which has Python API to send a local notebook for execution on a remote SLURM cluster, for example Comet, see &lt;a href=&quot;https://github.com/zonca/nbsubmit/blob/master/example/multiple_jobs/submit_multiple_jobs.ipynb&quot;&gt;an example&lt;/a&gt;. This project is not maintained right now.&lt;/li&gt;
  &lt;li&gt;Back in 2017 I tested submitting notebooks to Open Science Grid, see &lt;a href=&quot;https://github.com/zonca/batch-notebooks-condor&quot;&gt;the &lt;code class=&quot;highlighter-rouge&quot;&gt;batch-notebooks-condor&lt;/code&gt; repository&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Back in 2016 I created scripts to template a Jupyter Notebook and launch SLURM jobs, see &lt;a href=&quot;https://github.com/sdsc/sdsc-summer-institute-2016/blob/master/hpc3_python_hpc/slurm.shared.template&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;slurm.shared.template&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://github.com/sdsc/sdsc-summer-institute-2016/blob/master/hpc3_python_hpc/runipyloop.sh&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;runipyloop.sh&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Over the years, I have explored how to scale up easily computation through Jupyter Notebooks by executing them not-interactively, possibily parametrized and remotely. This is mostly for reference.</summary></entry><entry><title type="html">Deploy Cluster Autoscaler for Kubernetes on Jetstream</title><link href="https://zonca.dev/2019/09/kubernetes-jetstream-autoscaler.html" rel="alternate" type="text/html" title="Deploy Cluster Autoscaler for Kubernetes on Jetstream" /><published>2019-09-12T12:00:00-05:00</published><updated>2019-09-12T12:00:00-05:00</updated><id>https://zonca.dev/2019/09/kubernetes-jetstream-autoscaler</id><content type="html" xml:base="https://zonca.dev/2019/09/kubernetes-jetstream-autoscaler.html">&lt;p&gt;The &lt;a href=&quot;https://github.com/kubernetes/autoscaler&quot;&gt;Kubernetes Cluster Autoscaler&lt;/a&gt; is a service
that runs within a Kubernetes cluster and when there are not enough resources to accomodate
the pods that are queued to run, it contacts the API of the cloud provider to create
more Virtual Machines to join the Kubernetes Cluster.&lt;/p&gt;

&lt;p&gt;Initially the Cluster Autoscaler only supported commercial cloud provides, but back in
March 2019 &lt;a href=&quot;https://github.com/kubernetes/autoscaler/pull/1690&quot;&gt;a user contributed Openstack support based on Magnum&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;First step you should have a Magnum-based deployment running on Jetstream,
see &lt;a href=&quot;https://zonca.github.io/2019/06/kubernetes-jupyterhub-jetstream-magnum.html&quot;&gt;my recent tutorial about that&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Therefore you should also have already a copy of the repository of all configuration
files checked out on your local machine that you are using to interact with the openstack API,
if not:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone https://github.com/zonca/jupyterhub-deploy-kubernetes-jetstream.git
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and enter the folder dedicated to the autoscaler:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd jupyterhub-deploy-kubernetes-jetstream/kubernetes_magnum/autoscaler
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;setup-credentials&quot;&gt;Setup credentials&lt;/h2&gt;

&lt;p&gt;We first create the service account needed by the autoscaler to interact with the Kubernetes API:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; cluster-autoscaler-svcaccount.yaml 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then we need to provide all connection details for the autoscaler to interact with the Openstack API,
those are contained in the &lt;code class=&quot;highlighter-rouge&quot;&gt;cloud-config&lt;/code&gt; of our cluster available in the master node and setup
by Magnum.
Get the &lt;code class=&quot;highlighter-rouge&quot;&gt;IP&lt;/code&gt; of your master node from:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;openstack server list
&lt;span class=&quot;nv&quot;&gt;IP&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;xxx.xxx.xxx.xxx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now ssh into the master node and access the &lt;code class=&quot;highlighter-rouge&quot;&gt;cloud-config&lt;/code&gt; file:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh fedora@&lt;span class=&quot;nv&quot;&gt;$IP&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; /etc/kubernetes/cloud-config 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;now copy the &lt;code class=&quot;highlighter-rouge&quot;&gt;[Global]&lt;/code&gt; section at the end of &lt;code class=&quot;highlighter-rouge&quot;&gt;cluster-autoscaler-secret.yaml&lt;/code&gt; on the local machine.
Also remove the line of &lt;code class=&quot;highlighter-rouge&quot;&gt;ca-file&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; cluster-autoscaler-secret.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;launch-the-autoscaler-deployment&quot;&gt;Launch the Autoscaler deployment&lt;/h2&gt;

&lt;p&gt;Create the Autoscaler deployment:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; cluster-autoscaler-deployment-master.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Alternatively, I also added a version for a cluster where we are not deploying pods on master &lt;code class=&quot;highlighter-rouge&quot;&gt;cluster-autoscaler-deployment.yaml&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Check that the deployment is active:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; kube-system get pods
NAME                   DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
cluster-autoscaler     1         1         1            0           10s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And check its logs:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; kube-system logs cluster-autoscaler-59f4cf4f4-4k4p2

I0905 05:29:21.589062       1 leaderelection.go:217] attempting to acquire leader lease  kube-system/cluster-autoscaler...
I0905 05:29:39.412449       1 leaderelection.go:227] successfully acquired lease kube-system/cluster-autoscaler
I0905 05:29:43.896557       1 magnum_manager_heat.go:293] For stack ID 17ab3ae7-1a81-43e6-98ec-b6ffd04f91d3, stack name is k8s-lu3bksbwsln3
I0905 05:29:44.146319       1 magnum_manager_heat.go:310] Found nested kube_minions stack: name k8s-lu3bksbwsln3-kube_minions-r4lhlv5xuwu3, ID d0590824-cc70-4da5-b9ff-8581d99c666b
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you redeploy the cluster and keep a older authentication, you’ll see “Authentication failed” in the logs of the autoscaler pod, you need to update the secret every time you redeploy the cluster.&lt;/p&gt;

&lt;h2 id=&quot;test-the-autoscaler&quot;&gt;Test the autoscaler&lt;/h2&gt;

&lt;p&gt;Now we need to produce a significant load on the cluster so that the autoscaler is triggered to request Openstack Magnum to create more Virtual Machines.&lt;/p&gt;

&lt;p&gt;We can create a deployment of the NGINX container (any other would work for this test):&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create deployment autoscaler-demo &lt;span class=&quot;nt&quot;&gt;--image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;nginx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And then create a large number of replicas:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl scale deployment autoscaler-demo &lt;span class=&quot;nt&quot;&gt;--replicas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;300
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We are using 2 nodes with a large amount of memory and CPU, so they can accommodate more then 200 of those pods. The rest remains in the queue:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get deployment autoscaler-demo
NAME              DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
autoscaler-demo   300       300       300          213         18m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And this triggers the autoscaler:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; kube-system logs cluster-autoscaler-59f4cf4f4-4k4p2

I0905 05:34:47.401149       1 scale_up.go:689] Scale-up: setting group DefaultNodeGroup size to 2
I0905 05:34:49.267280       1 magnum_nodegroup.go:101] Increasing size by 1, 1-&amp;gt;2
I0905 05:35:22.222387       1 magnum_nodegroup.go:67] Waited &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;cluster UPDATE_IN_PROGRESS status
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Check also in the Openstack API:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;openstack coe cluster list
+------+------+---------+------------+--------------+--------------------+
| uuid | name | keypair | node_count | master_count | status             |
+------+------+---------+------------+--------------+--------------------+
| 09fcf| k8s  | comet   |          2 |            1 | UPDATE_IN_PROGRESS |
+------+------+---------+------------+--------------+--------------------+
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It takes about 4 minutes for a new VM to boot, be configured by Magnum and join the Kubernetes cluster.&lt;/p&gt;

&lt;p&gt;Checking the logs again should show another line:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;I0912 17:18:28.290987       1 magnum_nodegroup.go:67] Waited &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;cluster UPDATE_COMPLETE status
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Then you should have all 3 nodes available:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get nodes
NAME                        STATUS   ROLES    AGE   VERSION
k8s-6bawhy45wr5t-master-0   Ready    master   38m   v1.11.1
k8s-6bawhy45wr5t-minion-0   Ready    &amp;lt;none&amp;gt;   38m   v1.11.1
k8s-6bawhy45wr5t-minion-1   Ready    &amp;lt;none&amp;gt;   30m   v1.11.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and all 300 NGINX containers deployed:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get deployments
NAME              DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
autoscaler-demo   300       300       300          300         35m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You can also test scaling down by scaling back the number of NGINX containers to only a few and check in the logs
of the autoscaler that this process triggers the scale-down process.&lt;/p&gt;

&lt;p&gt;In &lt;code class=&quot;highlighter-rouge&quot;&gt;cluster-autoscaler-deployment-master.yaml&lt;/code&gt; I have configured the scale down process to trigger just after 1 minute, to simplify testing. For production, better increase this to 10 minutes or more. Check the &lt;a href=&quot;https://github.com/zonca/autoscaler/blob/cluster-autoscaler-1.14-magnum/cluster-autoscaler/FAQ.md&quot;&gt;documentation of Cluster Autoscaler 1.14&lt;/a&gt; for all other available options.&lt;/p&gt;

&lt;h2 id=&quot;note-about-the-cluster-autoscaler-container&quot;&gt;Note about the Cluster Autoscaler container&lt;/h2&gt;

&lt;p&gt;The Magnum provider was added in Cluster Autoscaler 1.15, however this version is not compatible with Kubernetes 1.11 which is currently available on Jetstream. Therefore I have taken the development version of Cluster Autoscaler 1.14 and compiled it myself. I also noticed that the scale down process was not working due to incompatible IDs when the Cloud Provider tried to lookup the ID of a Minion in the Stack. I am now directly using the MachineID instead of going through these indices. This version is available in &lt;a href=&quot;https://github.com/zonca/autoscaler/tree/cluster-autoscaler-1.14-magnum&quot;&gt;my fork of &lt;code class=&quot;highlighter-rouge&quot;&gt;autoscaler&lt;/code&gt;&lt;/a&gt; and it is built into docker containers on the &lt;a href=&quot;https://cloud.docker.com/repository/docker/zonca/k8s-cluster-autoscaler-jetstream&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;zonca/k8s-cluster-autoscaler-jetstream&lt;/code&gt; repository on Docker Hub&lt;/a&gt;.
The image tags are the short version of the repository git commit hash.&lt;/p&gt;

&lt;p&gt;I build the container using the &lt;code class=&quot;highlighter-rouge&quot;&gt;run_gobuilder.sh&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;run_build_autoscaler_container.sh&lt;/code&gt; scripts included in the repository.&lt;/p&gt;

&lt;h2 id=&quot;note-about-images-used-by-magnum&quot;&gt;Note about images used by Magnum&lt;/h2&gt;

&lt;p&gt;I have tested this deployment using the &lt;code class=&quot;highlighter-rouge&quot;&gt;Fedora-Atomic-27-20180419&lt;/code&gt; image on Jetstream at Indiana University.
The Fedora Atomic 28 image had a long hang-up during boot and took more than 10 minutes to start and that caused timeout in the autoscaler and anyway it would have been too long for a user waiting to start a notebook.&lt;/p&gt;

&lt;p&gt;I also tried updating the Fedora Atomic 28 image with &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo atomic host upgrade&lt;/code&gt; and while this fixed the slow startup issue, it generated a broken Kubernetes installation, i.e. the Kubernetes services didn’t detect the master node as part of the cluster, &lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl get nodes&lt;/code&gt; only showed the minion.&lt;/p&gt;</content><author><name></name></author><summary type="html">The Kubernetes Cluster Autoscaler is a service that runs within a Kubernetes cluster and when there are not enough resources to accomodate the pods that are queued to run, it contacts the API of the cloud provider to create more Virtual Machines to join the Kubernetes Cluster.</summary></entry></feed>